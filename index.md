## Graphics Portfolio
Hello, this is the portfolio of Theo Holmqvist Berlin, a Swedish MSc student. I study a course called 'Master of Science in Game and Software Development'. Below are rendering techniques and other graphics-programming related implementations I've made over the last couple of years.

### Volumetric Lighting
I've many times thought volumetric lighting in games have a 'wow effect'. So I implemented it myself whilst learning Vulkan. In the screenshot below, a directional light in the sky is emitting volumetric light.

![Volumetric Lighting](https://i.gyazo.com/30c8c096f3c22aae8b8a1eb4f9232308.jpg)

The core of the algorithm is surprisingly simple. A light texture is generated by raymarching through each pixel in a fragment shader. In each step of the raymarch, lighting calculations are performed using per-light parameters, and the light's shadow map is sampled to see if the point is in shadow or not.

I also implemented a shader that could generate volumetric light for point lights, but due to time restrictions I never got around to implementing the CPU-side code to handle it.

This implementation of volumetric lighting is of course very unoptimized. One possible method of optimizing it, as mentioned [in this slideshow](https://fr.slideshare.net/BenjaminGlatzel/volumetric-lighting-for-many-lights-in-lords-of-the-fallen), is to perform raymarching at a lower resolution, and then upscaling the results.

[Shader code](https://github.com/TheoBerlin/VulkanBoys/blob/master/Project/assets/shaders/volumetricLight/volumetricDirectionalFragment.glsl)

### Particles with Screen-Space Collisions
When I first checked out Star Citizen's Area 18, I saw an in-game holographic soda commercial emitting particles that could collide with geometry. They stood out to me, so in the same Vulkan application as above, I implemented particles with collisions.

![Particles](particles.gif)

The particle computation can be swapped between the CPU and the GPU at any time during runtime. When computed on the GPU, a compute shader is used and screen-space collisions can be enabled. Collisions are detected and resolved by utilizing the camera's depth buffer and G-buffer containing normals.

[Shader code](https://github.com/TheoBerlin/VulkanBoys/blob/master/Project/assets/shaders/particles/update_cs.glsl)

### Game Engine Supporting DirectX 11 and Vulkan
I have known DirectX 11 for some years. After recently learning Vulkan, I wanted to consolidate my knowledge of the API and see how it differs with DirectX 11. My idea of doing this was adding support for Vulkan to my game engine which previously only supported DirectX 11.

To support both rendering APIs, I made an API consisting of abstractions of core Vulkan objects such as Descriptor sets, pipelines, command lists etc. I made it this way to favor Vulkan, and to make the Vulkan implementation of the API simpler.

![API Files](https://i.gyazo.com/82545f2d0fdc9f5323ecae7d796b843b.png)

The DirectX 11 implementation of the API simulates said Vulkan objects. This was fun and insightful to do, as it highlighted some of the work that GPU drivers perform behind the curtains when running the higher level APIs of DirectX 11 and OpenGL. An obvious example of this would be the memory synchronizations that Vulkan has the application specify explicitly, whilst with DirectX 11, the driver figures out how and when to perform them.

[Folder shown above](https://github.com/TheoBerlin/SoloGame/tree/master/src/Engine/Rendering/APIAbstractions)

### Metaballs
Metaballs are masses that can merge together into a single body. I have implemented metaballs in different projects, using both marching cubes and raymarching.

#### Marching Cubes Metaballs
The metaballs seen below are implemented using marching cubes.

![Marching Cubes Metaballs](marchingCubes.gif)

This was done as part of a module called 'Large Game Project', in which me and nine other students together made a game from scratch. What you see above is a snippet of the project's trailer, available [here](https://www.youtube.com/watch?v=OKnG6HQkMr0).

We wanted the players' fired projectiles to look like animated blobs of paint or water, which visually matches what one can achieve with metaballs.

The algorithm for creating metaballs using marching cubes is properly explained by [Jamie Wong in his blog](http://jamie-wong.com/2014/08/19/metaballs-and-marching-squares/). Briefly summarized, the idea is to have a 3D grid, and generate density values (similar to a signed distance field) for each cell in the grid. Then, by looking at the density values of each corner of a cell, one can figure out if and how to generate triangles in a cell.

The implementation spans three compute shaders, where the first two compute density values and gradients for each cell corner in the grid, and the third generates mesh.

One of the challenges I faced when implementing marching cubes was that the amount of triangles needed to be consistent every frame. This was partly due to the project using raytracing and us wanting to avoid frequently updating Bottom Level Acceleration Structures (BLAS).

My solution for this issue was to hide 'unused' triangles inside one of the metaballs. Doing so whilst avoiding branching and special numbers (NaN and INF) was a fun challenge.

The shader code:<br/>
[Density](https://github.com/IbexOmega/CrazyCanvas/blob/master/Assets/Shaders/Projectiles/MarchingCubesDensity.comp)<br/>
[Gradient](https://github.com/IbexOmega/CrazyCanvas/blob/master/Assets/Shaders/Projectiles/MarchingCubesGradient.comp)<br/>
[Mesh Generation](https://github.com/IbexOmega/CrazyCanvas/blob/master/Assets/Shaders/Projectiles/MarchingCubesMeshGen.comp)

#### Raymarched Metaballs
The metaballs below are implemented using raymarching. At each step of the raymarch, a density value is calculated using the distance to each metaball. If the density is high enough, the 3D point is inside or on the surface of a metaball.

This was done as part of a course on WebGL in early 2019.

![Metaballs](metaballs.gif)

### Honorable Mentions
These are very minor techniques I implemented the first time I ever learned graphics programming with DirectX 11. They aren't worth putting on a pedestal, but they do deserve a bulleted list:
- FXAA
- Normal mapping
- Bump/Displacement mapping + Tessellation
